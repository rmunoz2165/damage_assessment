{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the word.csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the pictures\n",
    "# use google vision\n",
    "#create the csv file\n",
    "#save the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n",
    "from google.oauth2 import service_account\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_DIR = './Rubbled houses/'\n",
    "CONFIG_FILE = './config.json'\n",
    "WORDS_FILE = 'words_from_google_vision_1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_SERVICE_KEY = pd.read_json(CONFIG_FILE)[\"KEYS\"][\"GOOGLE_SERVICE_KEY\"]\n",
    "credentials = service_account.Credentials.from_service_account_file(GOOGLE_SERVICE_KEY)\n",
    "client = vision.ImageAnnotatorClient(credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_vision_words(file_name):\n",
    "\n",
    "    # Loads the image into memory\n",
    "    with io.open(file_name, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "    image = types.Image(content=content)\n",
    "    response = client.label_detection(image=image, max_results=100)\n",
    "    time.sleep(5)\n",
    "    res = MessageToDict(response)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(e, res, col_no):    \n",
    "    new_lst = []\n",
    "    for i in range(len(res[\"labelAnnotations\"])):\n",
    "        new_lst.append(res[\"labelAnnotations\"][i][\"description\"])\n",
    "    \n",
    "    return((e, new_lst)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_google_words_csv():\n",
    "    image_files = os.listdir(IMAGES_DIR)\n",
    "    label_d_lst = []\n",
    "    \n",
    "    for i, img in enumerate(image_files):\n",
    "        print(\"\\nReading  : {}\".format(img))\n",
    "        res = get_google_vision_words(IMAGES_DIR + img)\n",
    "        print(\"Got from vision  : {}\".format(img))\n",
    "        label_d_lst.append(get_labels(img, res, i))\n",
    "        print(\"Done : {}\".format(img))\n",
    "    \n",
    "    pd.DataFrame(label_d_lst).to_csv(WORDS_FILE)\n",
    "    print(\"{} saved\".format(WORDS_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the words file and build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "def get_estimator():\n",
    "    \n",
    "    data = pd.read_csv(WORDS_FILE)\n",
    "    data.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "    X=data[\"Words\"]\n",
    "    y=data[\"TRUE\"]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, stratify=y, test_size=0.20, random_state=42)\n",
    "    \n",
    "    params = {\n",
    "    1: {\"Pipeline\": [('vectorizer', CountVectorizer()),\n",
    "                     ('classifier', LogisticRegressionCV(random_state=42))],\n",
    "        \"hyper_params\": {\n",
    "            'vectorizer__ngram_range': [(1,1), (1,2), (1,3), (1,4)]}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    pipe = Pipeline(params[1][\"Pipeline\"])\n",
    "    hyper_params = params[1][\"hyper_params\"]\n",
    "\n",
    "    # Perform Grid Search\n",
    "    gridcv = GridSearchCV(pipe,\n",
    "                          param_grid=hyper_params,\n",
    "                          cv=5,\n",
    "                          scoring=\"accuracy\")\n",
    "    return gridcv.fit(X_train, y_train).best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Read the damaged photo\n",
    "## go to google vision and get the words\n",
    "## then predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'https://firebasestorage.googleapis.com/v0/b/fema-damage-report.appspot.com/o/images%2F1582004151708_15_25.jpg?alt=media&token=1c4eb4d0-c631-4159-9237-8d283cf23890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "def get_image_google_vision_words(url):\n",
    "\n",
    "    response_img = requests.get(url)\n",
    "    image = types.Image(content=response_img.content)\n",
    "    response = client.label_detection(image=image, max_results=100)\n",
    "    time.sleep(5)\n",
    "    res = MessageToDict(response)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(image_url): \n",
    "    \n",
    "    data_from_img = []\n",
    "    model = get_estimator()\n",
    "    res = get_image_google_vision_words(image_url)\n",
    "    data_from_img.append(get_labels(image_url, res, 0))\n",
    "    df = pd.DataFrame(data_from_img, columns=[\"url\", \"Words\"])\n",
    "    df[\"Words\"] = df[\"Words\"].astype(str)\n",
    "    \n",
    "    return model.predict(df[\"Words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "val = get_prediction(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
